{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"load_datasets.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"BwNfTPY3Gj2a"},"source":["import numpy as np \n","import os\n","import re      "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mzb_XblOGj2f"},"source":["import pandas as pd\n","from pandas import DataFrame\n","import random"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HYprBz14Gj2j"},"source":["column_names = [\"document\",\"sentiment\"]\n","train_data = []\n","\n","for dirname, _, filenames in os.walk('/[FILE_PATH]/aclImdb/train/pos'):\n","    for filename in filenames:\n","        file = open(os.path.join(dirname, filename), mode='r')\n","        content = file.read()\n","        file.close()\n","        train_data.append((re.sub('<br\\s?\\/>|<br>', \"\", content), 1))\n","\n","\n","for dirname, _, filenames in os.walk('/[FILE_PATH]/aclImdb/train/neg'):\n","    for filename in filenames:\n","        file = open(os.path.join(dirname, filename), mode='r')\n","        content = file.read()\n","        file.close()\n","        train_data.append((re.sub('<br\\s?\\/>|<br>', \"\", content), 0))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"geuyLXsnGj2m"},"source":["test_data_pos = []\n","test_data_neg = []\n","\n","for dirname, _, filenames in os.walk('/[FILE_PATH]/aclImdb/test/pos'):\n","    for filename in filenames:\n","        file = open(os.path.join(dirname, filename), mode='r')\n","        content = file.read()\n","        file.close()\n","        test_data_pos.append((re.sub('<br\\s?\\/>|<br>', \"\", content), 1))\n","\n","\n","for dirname, _, filenames in os.walk('/[FILE_PATH]/aclImdb/test/neg'):\n","    for filename in filenames:\n","        file = open(os.path.join(dirname, filename), mode='r')\n","        content = file.read()\n","        file.close()\n","        test_data_neg.append((re.sub('<br\\s?\\/>|<br>', \"\", content), 0))\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5L7qwkQNGj2p","outputId":"e3b236f2-1721-4fdb-cd64-ff003031e9d5"},"source":["# We want to enlarge the training dataset and create a validation dataset \n","# in the following way:\n","# Train 80% (40,000 examples), Validation 10%(5,000 examples), Test 10%(5,000 examples)\n","\n","# First, we shuffle the data\n","random.shuffle(test_data_pos)\n","random.shuffle(test_data_neg)\n","\n","# add some train data from the test data\n","train_data.extend(test_data_pos[0:7500])\n","train_data.extend(test_data_neg[0:7500])\n","random.shuffle(train_data)\n","\n","# reset the remaing data\n","test_data_pos = test_data_pos[7500:]\n","test_data_neg = test_data_neg[7500:]\n","\n","# add some validation data from the test data\n","validation_data = []\n","validation_data.extend(test_data_pos[0:2500])\n","validation_data.extend(test_data_neg[0:2500])\n","random.shuffle(validation_data)\n","\n","# reset the remaining data\n","test_data_pos = test_data_pos[2500:]\n","test_data_neg = test_data_neg[2500:]\n","\n","# remaining test data\n","test_data_pos.extend(test_data_neg)\n","test_data = test_data_pos\n","random.shuffle(test_data)\n","\n","print(np.array(train_data).shape)\n","print(np.array(validation_data).shape)\n","print(np.array(test_data).shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(40000, 2)\n","(5000, 2)\n","(5000, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jmMCxwcoGj2t","outputId":"ebc7c67d-d1a2-45bd-8d6a-da8973e67133"},"source":["train_df = DataFrame(train_data, columns=column_names) \n","validation_df = DataFrame(validation_data, columns=column_names) \n","test_df = DataFrame(test_data, columns=column_names)\n","\n","display(train_df.head())\n","print(len(train_df))\n","display(validation_df.head())\n","print(len(validation_df))\n","display(test_df.head())\n","print(len(test_df))\n","\n","train_df.to_csv('train.csv')\n","validation_df.to_csv('validation.csv')\n","test_df.to_csv('test.csv')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>document</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>As talk-shows go, Larry King Live is not bad, ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>This movie was made on a relatively small budg...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I had the misfortune to sit through the full 1...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>This movie is the very worst that I have ever ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>I would never have thought I would almost cry ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            document  sentiment\n","0  As talk-shows go, Larry King Live is not bad, ...          1\n","1  This movie was made on a relatively small budg...          1\n","2  I had the misfortune to sit through the full 1...          0\n","3  This movie is the very worst that I have ever ...          0\n","4  I would never have thought I would almost cry ...          1"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["40000\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>document</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Don't quite know why some people complain abou...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>The Kite Runner was beautiful, poignant and ve...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I absolutely loved this movie! It's my number ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>I could not watch more than 10 minutes of this...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>This movie doesn't even deserve a 1/10 This mo...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            document  sentiment\n","0  Don't quite know why some people complain abou...          1\n","1  The Kite Runner was beautiful, poignant and ve...          1\n","2  I absolutely loved this movie! It's my number ...          1\n","3  I could not watch more than 10 minutes of this...          0\n","4  This movie doesn't even deserve a 1/10 This mo...          0"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["5000\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>document</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Slow, odd film that drags and plods (I mean re...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Yes, in this movie you are treated to multiple...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I had only written one review on IMDb prior to...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Like Steven Seagal I also am a big Van Damme f...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>This is a wonderful old fashioned Christmas fa...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            document  sentiment\n","0  Slow, odd film that drags and plods (I mean re...          0\n","1  Yes, in this movie you are treated to multiple...          0\n","2  I had only written one review on IMDb prior to...          1\n","3  Like Steven Seagal I also am a big Van Damme f...          1\n","4  This is a wonderful old fashioned Christmas fa...          1"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["5000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"buZNl4JMGj2w"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P3l5eWvRGj20"},"source":["#def clean_tweet(tweet):\n","#    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"70O6lndXGj23"},"source":[""],"execution_count":null,"outputs":[]}]}